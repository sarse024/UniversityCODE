# Video Inference with MindYOLO and MindSpore

This repository contains a video inference application built using the [MindSpore](https://www.mindspore.cn/en) framework and the [MindYOLO](https://github.com/mindspore-lab/mindyolo) model zoo. It performs real-time object detection and identity tracking on video files using a lightweight YOLOv8n model and a custom-built tracking system.

## üìå Project Overview

The system is designed as a modular video processing pipeline composed of:

- **Object Detection**: Uses a pretrained YOLOv8n model to identify objects in each frame.
- **Identity Tracking**: Maintains consistent object IDs across frames using a normalized-distance proximity algorithm.
- **Visualization Engine**: Overlays bounding boxes, unique IDs, motion trails, and counters on the video output.

> ‚ö†Ô∏è This project is a proof-of-concept aimed at learning the MindSpore ecosystem. It is not production-grade and can benefit from future optimizations and improved tracking algorithms.

## üñ•Ô∏è Example Use Case

The model has been tested on various scenarios including:
- Pet movement (e.g. dogs)
- Street traffic from surveillance footage
- Crowded pedestrian areas

While it performs well in simple environments, it may struggle in occluded or densely packed scenes due to its basic tracking mechanism.

## üì¶ Installation Guide

### üîß Prerequisites

Before you begin, make sure you have the following installed:

- Python ‚â• 3.8
- [MindSpore](https://www.mindspore.cn/en) (with appropriate backend: CPU, GPU, or Ascend)
- `pip` or `conda` for package management

### üêç Recommended Installation Steps

```bash
# (Optional) Create a virtual environment
python -m venv mindyolo-env
source mindyolo-env/bin/activate  # On Windows: mindyolo-env\Scripts\activate

# Clone the repository
git clone https://github.com/your-username/video-inference-mindyolo.git
cd video-inference-mindyolo

# Install dependencies
pip install -r requirements.txt
